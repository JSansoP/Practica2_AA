{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "209177da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os, glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d65f689",
   "metadata": {},
   "source": [
    "# Create Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d523f51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_IMAGES_TRAIN = 20_000\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "TEST_BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d22e812",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#First we define a custom dataset class to be able to create the DataLoader properly\n",
    "\n",
    "class CustomImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, labels_file, img_dir, separator=',', img_type=\"png\",transform=None, max_images=None):\n",
    "        # As labels, we select the 'c' column of the dataset, which contains the number\n",
    "        # of circles of the image\n",
    "        aux = pd.read_csv(labels_file,sep=separator)\n",
    "        aux.drop(columns=aux.columns[0], axis=1,inplace=True)\n",
    "        aux.drop(columns=aux.columns[1:], axis=1, inplace=True)\n",
    "        self.img_labels = aux.to_numpy().squeeze()\n",
    "        if max_images is not None:\n",
    "            self.img_labels = self.img_labels[:max_images]\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.img_type = img_type\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # To get the images, we transform the index to a 5 long string (so 28 -> 00028)\n",
    "        # and we use that to read the image.\n",
    "        img_name = str(idx).zfill(5)+'.'+self.img_type\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = cv2.imread(img_path,  cv2.IMREAD_GRAYSCALE)\n",
    "        label = self.img_labels[idx,]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            image = image.float()\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "475c69af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Testing custom dataset is correctly constructed\n",
    "#dummy_dataset = CustomImageDataset(labels_file='data/val/dades.csv', img_dir='data/val', separator=';')\n",
    "#batch = next(iter(dummy_dataset))\n",
    "#plt.imshow(batch[0], cmap='gray')\n",
    "#plt.show()\n",
    "#print(batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eff0293c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128,128))\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = CustomImageDataset(labels_file='data/train/dades.csv',img_dir='data/train', separator=';',max_images=20_000\n",
    "                                  ,transform=transform)\n",
    "test_dataset = CustomImageDataset(labels_file='data/val/dades.csv',img_dir='data/val',separator=';',transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, TRAIN_BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edd8121f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class FullyConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FullyConvNet, self).__init__()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv_1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.conv_2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.conv_3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.conv_4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size = 3, stride=1, padding=\"same\")\n",
    "        self.linear1 = nn.Linear(8*8*128,256)\n",
    "        self.linear2 = nn.Linear(256,1)\n",
    "        self.relu =nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.max_pool(x) #out = 64x64\n",
    "        x = self.conv_2(x)\n",
    "        x = self.max_pool(x) #out = 32x32\n",
    "        x = self.conv_3(x)\n",
    "        x = self.max_pool(x) # out = 16x16\n",
    "        x = self.conv_4(x)\n",
    "        x = self.max_pool(x) # out = 8x8 * 128\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        output = self.linear2(x)\n",
    "        \n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aaa6f05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, log_interval=100, verbose=True):\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    loss_v = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0 and verbose:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Average: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item(), loss.item()/ len(data)))\n",
    "        loss_v += loss.item()\n",
    "\n",
    "    loss_v /= len(train_loader.dataset)\n",
    "    print('\\nTrain set: Average loss: {:.4f}\\n'.format(loss_v))\n",
    " \n",
    "    return loss_v\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_func(output, target)\n",
    "            output = torch.round(output)\n",
    "            correct += output.eq(target.view_as(output)).sum().item()\n",
    " \n",
    "  \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e730055",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters  2194817\n",
      "Train Epoch: 0 [0/20000 (0%)]\tLoss: 1.680200, Average: 0.013127\n",
      "Train Epoch: 0 [12800/20000 (64%)]\tLoss: 0.498992, Average: 0.003898\n",
      "\n",
      "Train set: Average loss: 0.0041\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0039, Accuracy: 0/2000 (0%)\n",
      "\n",
      "Train Epoch: 1 [0/20000 (0%)]\tLoss: 0.344629, Average: 0.002692\n"
     ]
    }
   ],
   "source": [
    "use_cuda = True\n",
    "torch.manual_seed(33)\n",
    "\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "epochs = 20\n",
    "lr = 0.001\n",
    "\n",
    "model = FullyConvNet().to(device)\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad) # !!!\n",
    "\n",
    "print(\"Parameters \",pytorch_total_params)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "# Guardam el valor de peèrdua mig de cada iteració (època)\n",
    "train_l = np.zeros((epochs))\n",
    "test_l = np.zeros((epochs))\n",
    "\n",
    "# Bucle d'entrenament\n",
    "for epoch in range(0, epochs):\n",
    "    train_l[epoch] = train(model, device, train_loader, optimizer, epoch)\n",
    "    test_l[epoch]  = test(model, device, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
