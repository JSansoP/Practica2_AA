{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "209177da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os, glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d65f689",
   "metadata": {},
   "source": [
    "# Create Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d523f51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_IMAGES_TRAIN = 20_000\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "TEST_BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d22e812",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#First we define a custom dataset class to be able to create the DataLoader properly\n",
    "\n",
    "class CustomImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, labels_file, img_dir, separator=',', img_type=\"png\",transform=None, max_images=None):\n",
    "        # As labels, we select the 'c' column of the dataset, which contains the number\n",
    "        # of circles of the image\n",
    "        aux = pd.read_csv(labels_file,sep=separator)\n",
    "        aux.drop(columns=aux.columns[0], axis=1,inplace=True)\n",
    "        aux.drop(columns=aux.columns[1:], axis=1, inplace=True)\n",
    "        self.img_labels = aux.to_numpy().squeeze()\n",
    "        if max_images is not None:\n",
    "            self.img_labels = self.img_labels[:max_images]\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.img_type = img_type\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # To get the images, we transform the index to a 5 long string (so 28 -> 00028)\n",
    "        # and we use that to read the image.\n",
    "        img_name = str(idx).zfill(5)+'.'+self.img_type\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = cv2.imread(img_path,  cv2.IMREAD_GRAYSCALE)\n",
    "        label = self.img_labels[idx,]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            image = image.float()\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e97a42e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Testing custom dataset is correctly constructed\n",
    "#dummy_dataset = CustomImageDataset(labels_file='data/val/dades.csv', img_dir='data/val', separator=';')\n",
    "#batch = next(iter(dummy_dataset))\n",
    "#plt.imshow(batch[0], cmap='gray')\n",
    "#plt.show()\n",
    "#print(batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eff0293c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128,128))\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = CustomImageDataset(labels_file='data/train/dades.csv',img_dir='data/train', separator=';',max_images=20_000\n",
    "                                  ,transform=transform)\n",
    "test_dataset = CustomImageDataset(labels_file='data/val/dades.csv',img_dir='data/val',separator=';',transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, TRAIN_BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edd8121f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class FullyConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FullyConvNet, self).__init__()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv_1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.conv_2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.conv_3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.conv_4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size = 3, stride=1, padding=\"same\")\n",
    "        self.linear1 = nn.Linear(8*8*128,256)\n",
    "        self.linear2 = nn.Linear(256,1)\n",
    "        self.relu =nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.max_pool(x) #out = 64x64\n",
    "        x = self.conv_2(x)\n",
    "        x = self.max_pool(x) #out = 32x32\n",
    "        x = self.conv_3(x)\n",
    "        x = self.max_pool(x) # out = 16x16\n",
    "        x = self.conv_4(x)\n",
    "        x = self.max_pool(x) # out = 8x8 * 128\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        output = self.linear2(x)\n",
    "        \n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aaa6f05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, log_interval=100, verbose=True):\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    loss_v = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0 and verbose:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Average: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item(), loss.item()/ len(data)))\n",
    "        loss_v += loss.item()\n",
    "\n",
    "    loss_v /= len(train_loader.dataset)\n",
    "    print('\\nTrain set: Average loss: {:.4f}\\n'.format(loss_v))\n",
    " \n",
    "    return loss_v\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_func(output, target)\n",
    "            output = torch.round(output)\n",
    "            correct += output.eq(target.view_as(output)).sum().item()\n",
    " \n",
    "  \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e730055",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters  2194817\n",
      "Train Epoch: 0 [0/20000 (0%)]\tLoss: 1.680200, Average: 0.013127\n",
      "Train Epoch: 0 [12800/20000 (64%)]\tLoss: 0.499701, Average: 0.003904\n",
      "\n",
      "Train set: Average loss: 0.0041\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0039, Accuracy: 1055/2000 (53%)\n",
      "\n",
      "Train Epoch: 1 [0/20000 (0%)]\tLoss: 0.349566, Average: 0.002731\n",
      "Train Epoch: 1 [12800/20000 (64%)]\tLoss: 0.373633, Average: 0.002919\n",
      "\n",
      "Train set: Average loss: 0.0028\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0045, Accuracy: 1030/2000 (52%)\n",
      "\n",
      "Train Epoch: 2 [0/20000 (0%)]\tLoss: 0.372009, Average: 0.002906\n",
      "Train Epoch: 2 [12800/20000 (64%)]\tLoss: 0.205607, Average: 0.001606\n",
      "\n",
      "Train set: Average loss: 0.0014\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0018, Accuracy: 1495/2000 (75%)\n",
      "\n",
      "Train Epoch: 3 [0/20000 (0%)]\tLoss: 0.162391, Average: 0.001269\n",
      "Train Epoch: 3 [12800/20000 (64%)]\tLoss: 0.054401, Average: 0.000425\n",
      "\n",
      "Train set: Average loss: 0.0005\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 1876/2000 (94%)\n",
      "\n",
      "Train Epoch: 4 [0/20000 (0%)]\tLoss: 0.056625, Average: 0.000442\n",
      "Train Epoch: 4 [12800/20000 (64%)]\tLoss: 0.045559, Average: 0.000356\n",
      "\n",
      "Train set: Average loss: 0.0004\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 1911/2000 (96%)\n",
      "\n",
      "Train Epoch: 5 [0/20000 (0%)]\tLoss: 0.045166, Average: 0.000353\n",
      "Train Epoch: 5 [12800/20000 (64%)]\tLoss: 0.027543, Average: 0.000215\n",
      "\n",
      "Train set: Average loss: 0.0003\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 1927/2000 (96%)\n",
      "\n",
      "Train Epoch: 6 [0/20000 (0%)]\tLoss: 0.038373, Average: 0.000300\n",
      "Train Epoch: 6 [12800/20000 (64%)]\tLoss: 0.021987, Average: 0.000172\n",
      "\n",
      "Train set: Average loss: 0.0002\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 1952/2000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/20000 (0%)]\tLoss: 0.025858, Average: 0.000202\n",
      "Train Epoch: 7 [12800/20000 (64%)]\tLoss: 0.018296, Average: 0.000143\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Bucle d'entrenament\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, epochs):\n\u001b[1;32m---> 26\u001b[0m     train_l[epoch] \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     test_l[epoch]  \u001b[38;5;241m=\u001b[39m test(model, device, test_loader)\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, device, train_loader, optimizer, epoch, log_interval, verbose)\u001b[0m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      5\u001b[0m loss_v \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m      9\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     10\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(data)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torchCUDA\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torchCUDA\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torchCUDA\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torchCUDA\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mCustomImageDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     23\u001b[0m img_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(idx)\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_type\n\u001b[0;32m     24\u001b[0m img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_dir, img_name)\n\u001b[1;32m---> 25\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMREAD_GRAYSCALE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_labels[idx,]\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "use_cuda = True\n",
    "torch.manual_seed(33)\n",
    "\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "epochs = 20\n",
    "lr = 0.001\n",
    "\n",
    "model = FullyConvNet().to(device)\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad) # !!!\n",
    "\n",
    "print(\"Parameters \",pytorch_total_params)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "# Guardam el valor de peèrdua mig de cada iteració (època)\n",
    "train_l = np.zeros((epochs))\n",
    "test_l = np.zeros((epochs))\n",
    "\n",
    "# Bucle d'entrenament\n",
    "for epoch in range(0, epochs):\n",
    "    train_l[epoch] = train(model, device, train_loader, optimizer, epoch)\n",
    "    test_l[epoch]  = test(model, device, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
