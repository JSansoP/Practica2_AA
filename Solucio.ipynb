{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "209177da",
   "metadata": {
    "id": "209177da",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os, glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d65f689",
   "metadata": {
    "id": "1d65f689"
   },
   "source": [
    "# Create Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d523f51",
   "metadata": {
    "id": "4d523f51",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_IMAGES_TRAIN = 50_000\n",
    "TRAIN_BATCH_SIZE = 256\n",
    "TEST_BATCH_SIZE = 100\n",
    "SAVE_MODEL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e272af58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "use_cuda = True\n",
    "torch.manual_seed(33)\n",
    "\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    print(\"Using CUDA\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d22e812",
   "metadata": {
    "id": "9d22e812",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First we define a custom dataset class to be able to create the DataLoader properly\n",
    "\n",
    "class CustomImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, labels_file, img_dir, separator=',', img_type=\"png\",transform=None, max_images=None, toColor=False):\n",
    "        # As labels, we select the 'c' column of the dataset, which contains the number\n",
    "        # of circles of the image\n",
    "        aux = pd.read_csv(labels_file,sep=separator)\n",
    "        aux.drop(columns=aux.columns[0], axis=1,inplace=True)\n",
    "        aux.drop(columns=aux.columns[1:], axis=1, inplace=True)\n",
    "        self.img_labels = aux.to_numpy().squeeze()\n",
    "        if max_images is not None:\n",
    "            self.img_labels = self.img_labels[:max_images]\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.img_type = img_type\n",
    "        self.toColor = toColor\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # To get the images, we transform the index to a 5 long string (so 28 -> 00028)\n",
    "        # and we use that to read the image.\n",
    "        img_name = str(idx).zfill(5)+'.'+self.img_type\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if self.toColor:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "        label = self.img_labels[idx,]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            image = image.float()\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e97a42e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "e97a42e8",
    "outputId": "153afff7-978b-4ffc-f782-1f99606a8c20",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "# Testing custom dataset is correctly constructed\n",
    "dummy_dataset = CustomImageDataset(labels_file='data/val/dades.csv', img_dir='data/val', separator=';')\n",
    "batch = next(iter(dummy_dataset))\n",
    "plt.imshow(batch[0], cmap='gray')\n",
    "plt.show()\n",
    "print(batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eff0293c",
   "metadata": {
    "id": "eff0293c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128,128))\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = CustomImageDataset(labels_file='data/train/dades.csv', img_dir='data/train', separator=';', max_images=N_IMAGES_TRAIN, transform=transform)\n",
    "test_dataset = CustomImageDataset(labels_file='data/val/dades.csv', img_dir='data/val', separator=';', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, TRAIN_BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edd8121f",
   "metadata": {
    "id": "edd8121f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ConvNet1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet1, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.conv2 = nn.Conv2d(in_channels=2, out_channels=4, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.conv3 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.conv4 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.conv5 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.conv6 = nn.Conv2d(in_channels=8, out_channels=4, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.conv7 = nn.Conv2d(in_channels=4, out_channels=2, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.conv8 = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.linear = nn.Linear(8*8, 32)\n",
    "        self.linear2 = nn.Linear(32, 1)\n",
    "        self.relu =nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.max_pool(x) # out = 64x64x2\n",
    "        x = self.conv2(x)\n",
    "        x = self.max_pool(x) # out = 32x32x4\n",
    "        x = self.conv3(x)\n",
    "        x = self.max_pool(x) # out = 16x16x8\n",
    "        x = self.conv4(x)\n",
    "        x = self.max_pool(x) # out = 8x8x16\n",
    "        x = self.conv5(x)    # out = 8x8x8\n",
    "        x = self.conv6(x)    # out = 8x8x4\n",
    "        x = self.conv7(x)    # out = 8x8x2\n",
    "        x = self.conv8(x)    # out = 8x8x1\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.linear(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aaa6f05",
   "metadata": {
    "id": "6aaa6f05",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, log_interval=100, verbose=True):\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    loss_v = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0 and verbose:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Average: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item(), loss.item()/ len(data)))\n",
    "        loss_v += loss.item()\n",
    "\n",
    "    loss_v /= len(train_loader.dataset)\n",
    "    print('\\nTrain set: Average loss: {:.4f}\\n'.format(loss_v))\n",
    " \n",
    "    return loss_v\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_func(output, target)\n",
    "            output = torch.round(output)\n",
    "            correct += output.eq(target.view_as(output)).sum().item()\n",
    " \n",
    "  \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e730055",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4e730055",
    "outputId": "ce606c88-b461-4518-c2a2-dc5863257b4e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Parameters  5218\n",
      "Train Epoch: 0 [0/50000 (0%)]\tLoss: 1.288126, Average: 0.005032\n",
      "Train Epoch: 0 [25600/50000 (51%)]\tLoss: 0.659833, Average: 0.002577\n",
      "\n",
      "Train set: Average loss: 0.0027\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0065, Accuracy: 694/2000 (35%)\n",
      "\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 0.664953, Average: 0.002597\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 0.659193, Average: 0.002575\n",
      "\n",
      "Train set: Average loss: 0.0026\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0065, Accuracy: 694/2000 (35%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.660427, Average: 0.002580\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 0.670775, Average: 0.002620\n",
      "\n",
      "Train set: Average loss: 0.0023\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0052, Accuracy: 930/2000 (46%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.467475, Average: 0.001826\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.487166, Average: 0.001903\n",
      "\n",
      "Train set: Average loss: 0.0017\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0048, Accuracy: 949/2000 (47%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.411448, Average: 0.001607\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.391633, Average: 0.001530\n",
      "\n",
      "Train set: Average loss: 0.0014\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0036, Accuracy: 1094/2000 (55%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.307159, Average: 0.001200\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.275933, Average: 0.001078\n",
      "\n",
      "Train set: Average loss: 0.0012\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 1443/2000 (72%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.211241, Average: 0.000825\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.290063, Average: 0.001133\n",
      "\n",
      "Train set: Average loss: 0.0010\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0027, Accuracy: 1343/2000 (67%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.287699, Average: 0.001124\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.191991, Average: 0.000750\n",
      "\n",
      "Train set: Average loss: 0.0009\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0021, Accuracy: 1467/2000 (73%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.208307, Average: 0.000814\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.171459, Average: 0.000670\n",
      "\n",
      "Train set: Average loss: 0.0007\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0018, Accuracy: 1525/2000 (76%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.182093, Average: 0.000711\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.203343, Average: 0.000794\n",
      "\n",
      "Train set: Average loss: 0.0007\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 1594/2000 (80%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.157143, Average: 0.000614\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.185441, Average: 0.000724\n",
      "\n",
      "Train set: Average loss: 0.0006\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0014, Accuracy: 1652/2000 (83%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.130785, Average: 0.000511\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.168435, Average: 0.000658\n",
      "\n",
      "Train set: Average loss: 0.0006\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 1698/2000 (85%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.112858, Average: 0.000441\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 0.163966, Average: 0.000640\n",
      "\n",
      "Train set: Average loss: 0.0005\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 1689/2000 (84%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.123240, Average: 0.000481\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 0.162743, Average: 0.000636\n",
      "\n",
      "Train set: Average loss: 0.0005\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 1742/2000 (87%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.105426, Average: 0.000412\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 0.183623, Average: 0.000717\n",
      "\n",
      "Train set: Average loss: 0.0004\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0009, Accuracy: 1763/2000 (88%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.097318, Average: 0.000380\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 0.163470, Average: 0.000639\n",
      "\n",
      "Train set: Average loss: 0.0004\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0008, Accuracy: 1803/2000 (90%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 0.083620, Average: 0.000327\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 0.164015, Average: 0.000641\n",
      "\n",
      "Train set: Average loss: 0.0004\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0007, Accuracy: 1821/2000 (91%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 0.077072, Average: 0.000301\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 0.082992, Average: 0.000324\n",
      "\n",
      "Train set: Average loss: 0.0003\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0007, Accuracy: 1837/2000 (92%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 0.067093, Average: 0.000262\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 0.158706, Average: 0.000620\n",
      "\n",
      "Train set: Average loss: 0.0003\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0007, Accuracy: 1852/2000 (93%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.060772, Average: 0.000237\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 0.079878, Average: 0.000312\n",
      "\n",
      "Train set: Average loss: 0.0003\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 1845/2000 (92%)\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 0.060144, Average: 0.000235\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 0.171222, Average: 0.000669\n",
      "\n",
      "Train set: Average loss: 0.0003\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 1864/2000 (93%)\n",
      "\n",
      "Train Epoch: 21 [0/50000 (0%)]\tLoss: 0.051052, Average: 0.000199\n",
      "Train Epoch: 21 [25600/50000 (51%)]\tLoss: 0.065434, Average: 0.000256\n",
      "\n",
      "Train set: Average loss: 0.0003\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 1868/2000 (93%)\n",
      "\n",
      "Train Epoch: 22 [0/50000 (0%)]\tLoss: 0.050624, Average: 0.000198\n",
      "Train Epoch: 22 [25600/50000 (51%)]\tLoss: 0.071363, Average: 0.000279\n",
      "\n",
      "Train set: Average loss: 0.0003\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 1889/2000 (94%)\n",
      "\n",
      "Train Epoch: 23 [0/50000 (0%)]\tLoss: 0.043222, Average: 0.000169\n",
      "Train Epoch: 23 [25600/50000 (51%)]\tLoss: 0.053677, Average: 0.000210\n",
      "\n",
      "Train set: Average loss: 0.0002\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 1893/2000 (95%)\n",
      "\n",
      "Train Epoch: 24 [0/50000 (0%)]\tLoss: 0.038981, Average: 0.000152\n",
      "Train Epoch: 24 [25600/50000 (51%)]\tLoss: 0.049526, Average: 0.000193\n",
      "\n",
      "Train set: Average loss: 0.0002\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 1888/2000 (94%)\n",
      "\n",
      "Train Epoch: 25 [0/50000 (0%)]\tLoss: 0.043108, Average: 0.000168\n",
      "Train Epoch: 25 [25600/50000 (51%)]\tLoss: 0.046903, Average: 0.000183\n",
      "\n",
      "Train set: Average loss: 0.0002\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 1905/2000 (95%)\n",
      "\n",
      "Train Epoch: 26 [0/50000 (0%)]\tLoss: 0.033425, Average: 0.000131\n",
      "Train Epoch: 26 [25600/50000 (51%)]\tLoss: 0.042238, Average: 0.000165\n",
      "\n",
      "Train set: Average loss: 0.0002\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 1902/2000 (95%)\n",
      "\n",
      "Train Epoch: 27 [0/50000 (0%)]\tLoss: 0.036739, Average: 0.000144\n",
      "Train Epoch: 27 [25600/50000 (51%)]\tLoss: 0.044794, Average: 0.000175\n",
      "\n",
      "Train set: Average loss: 0.0002\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 1898/2000 (95%)\n",
      "\n",
      "Train Epoch: 28 [0/50000 (0%)]\tLoss: 0.037820, Average: 0.000148\n",
      "Train Epoch: 28 [25600/50000 (51%)]\tLoss: 0.045383, Average: 0.000177\n",
      "\n",
      "Train set: Average loss: 0.0002\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 1908/2000 (95%)\n",
      "\n",
      "Train Epoch: 29 [0/50000 (0%)]\tLoss: 0.033320, Average: 0.000130\n",
      "Train Epoch: 29 [25600/50000 (51%)]\tLoss: 0.038321, Average: 0.000150\n",
      "\n",
      "Train set: Average loss: 0.0002\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 1908/2000 (95%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 30\n",
    "lr = 0.1\n",
    "\n",
    "model = ConvNet1().to(device)\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad) # !!!\n",
    "\n",
    "print(\"Parameters \", pytorch_total_params)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "loss_func = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Guardam el valor de pèrdua promig de cada iteració (època)\n",
    "train_l = np.zeros((epochs))\n",
    "test_l = np.zeros((epochs))\n",
    "\n",
    "# Bucle d'entrenament\n",
    "for epoch in range(0, epochs):\n",
    "    train_l[epoch] = train(model, device, train_loader, optimizer, epoch)\n",
    "    test_l[epoch]  = test(model, device, test_loader)\n",
    "    \n",
    "if SAVE_MODEL:\n",
    "    torch.save(model, \"ConvNet1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9ac836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetOneLinearLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNetOneLinearLayer, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.conv2 = nn.Conv2d(in_channels=2, out_channels=4, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.conv3 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.conv4 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.conv5 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.conv6 = nn.Conv2d(in_channels=8, out_channels=4, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.conv7 = nn.Conv2d(in_channels=4, out_channels=2, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.conv8 = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.linear = nn.Linear(8*8, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.max_pool(x) # out = 64x64x2\n",
    "        x = self.conv2(x)\n",
    "        x = self.max_pool(x) # out = 32x32x4\n",
    "        x = self.conv3(x)\n",
    "        x = self.max_pool(x) # out = 16x16x8\n",
    "        x = self.conv4(x)\n",
    "        x = self.max_pool(x) # out = 8x8x16\n",
    "        x = self.conv5(x)    # out = 8x8x8\n",
    "        x = self.conv6(x)    # out = 8x8x4\n",
    "        x = self.conv7(x)    # out = 8x8x2\n",
    "        x = self.conv8(x)    # out = 8x8x1\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.linear(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6064bd35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters  3170\n",
      "Train Epoch: 0 [0/50000 (0%)]\tLoss: 1.678131, Average: 0.006555\n",
      "Train Epoch: 0 [25600/50000 (51%)]\tLoss: 0.660630, Average: 0.002581\n",
      "\n",
      "Train set: Average loss: 0.0027\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0065, Accuracy: 694/2000 (35%)\n",
      "\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 0.665083, Average: 0.002598\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 0.658934, Average: 0.002574\n",
      "\n",
      "Train set: Average loss: 0.0026\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0065, Accuracy: 694/2000 (35%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.663460, Average: 0.002592\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 0.656293, Average: 0.002564\n",
      "\n",
      "Train set: Average loss: 0.0026\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0063, Accuracy: 694/2000 (35%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.639787, Average: 0.002499\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.557887, Average: 0.002179\n",
      "\n",
      "Train set: Average loss: 0.0022\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0044, Accuracy: 993/2000 (50%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.400655, Average: 0.001565\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.407330, Average: 0.001591\n",
      "\n",
      "Train set: Average loss: 0.0015\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0030, Accuracy: 1257/2000 (63%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.291764, Average: 0.001140\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.330586, Average: 0.001291\n",
      "\n",
      "Train set: Average loss: 0.0013\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0028, Accuracy: 1315/2000 (66%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.292640, Average: 0.001143\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.243891, Average: 0.000953\n",
      "\n",
      "Train set: Average loss: 0.0011\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0031, Accuracy: 1228/2000 (61%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.280616, Average: 0.001096\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.209933, Average: 0.000820\n",
      "\n",
      "Train set: Average loss: 0.0010\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0025, Accuracy: 1360/2000 (68%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.280568, Average: 0.001096\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.211105, Average: 0.000825\n",
      "\n",
      "Train set: Average loss: 0.0009\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0019, Accuracy: 1531/2000 (77%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.201624, Average: 0.000788\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.180537, Average: 0.000705\n",
      "\n",
      "Train set: Average loss: 0.0008\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 1600/2000 (80%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.163942, Average: 0.000640\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.164459, Average: 0.000642\n",
      "\n",
      "Train set: Average loss: 0.0007\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 1633/2000 (82%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.156137, Average: 0.000610\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.134321, Average: 0.000525\n",
      "\n",
      "Train set: Average loss: 0.0007\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0014, Accuracy: 1632/2000 (82%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.152937, Average: 0.000597\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 0.141176, Average: 0.000551\n",
      "\n",
      "Train set: Average loss: 0.0006\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 1673/2000 (84%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.134498, Average: 0.000525\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 0.130666, Average: 0.000510\n",
      "\n",
      "Train set: Average loss: 0.0006\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 1712/2000 (86%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.116162, Average: 0.000454\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 0.119729, Average: 0.000468\n",
      "\n",
      "Train set: Average loss: 0.0006\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 1727/2000 (86%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.113379, Average: 0.000443\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 0.114357, Average: 0.000447\n",
      "\n",
      "Train set: Average loss: 0.0005\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 1731/2000 (87%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 0.119541, Average: 0.000467\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 0.102366, Average: 0.000400\n",
      "\n",
      "Train set: Average loss: 0.0005\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 1720/2000 (86%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 0.131023, Average: 0.000512\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 0.090899, Average: 0.000355\n",
      "\n",
      "Train set: Average loss: 0.0004\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 1686/2000 (84%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 0.138863, Average: 0.000542\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 0.085142, Average: 0.000333\n",
      "\n",
      "Train set: Average loss: 0.0004\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 1727/2000 (86%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.123409, Average: 0.000482\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 0.078443, Average: 0.000306\n",
      "\n",
      "Train set: Average loss: 0.0004\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 1767/2000 (88%)\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 0.105773, Average: 0.000413\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 0.071734, Average: 0.000280\n",
      "\n",
      "Train set: Average loss: 0.0004\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0009, Accuracy: 1787/2000 (89%)\n",
      "\n",
      "Train Epoch: 21 [0/50000 (0%)]\tLoss: 0.096267, Average: 0.000376\n",
      "Train Epoch: 21 [25600/50000 (51%)]\tLoss: 0.068992, Average: 0.000269\n",
      "\n",
      "Train set: Average loss: 0.0003\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0009, Accuracy: 1795/2000 (90%)\n",
      "\n",
      "Train Epoch: 22 [0/50000 (0%)]\tLoss: 0.093682, Average: 0.000366\n",
      "Train Epoch: 22 [25600/50000 (51%)]\tLoss: 0.070129, Average: 0.000274\n",
      "\n",
      "Train set: Average loss: 0.0003\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0008, Accuracy: 1808/2000 (90%)\n",
      "\n",
      "Train Epoch: 23 [0/50000 (0%)]\tLoss: 0.085060, Average: 0.000332\n",
      "Train Epoch: 23 [25600/50000 (51%)]\tLoss: 0.067662, Average: 0.000264\n",
      "\n",
      "Train set: Average loss: 0.0003\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0008, Accuracy: 1815/2000 (91%)\n",
      "\n",
      "Train Epoch: 24 [0/50000 (0%)]\tLoss: 0.079384, Average: 0.000310\n",
      "Train Epoch: 24 [25600/50000 (51%)]\tLoss: 0.070074, Average: 0.000274\n",
      "\n",
      "Train set: Average loss: 0.0003\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0008, Accuracy: 1821/2000 (91%)\n",
      "\n",
      "Train Epoch: 25 [0/50000 (0%)]\tLoss: 0.077050, Average: 0.000301\n",
      "Train Epoch: 25 [25600/50000 (51%)]\tLoss: 0.063827, Average: 0.000249\n",
      "\n",
      "Train set: Average loss: 0.0003\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0008, Accuracy: 1825/2000 (91%)\n",
      "\n",
      "Train Epoch: 26 [0/50000 (0%)]\tLoss: 0.074316, Average: 0.000290\n",
      "Train Epoch: 26 [25600/50000 (51%)]\tLoss: 0.063481, Average: 0.000248\n",
      "\n",
      "Train set: Average loss: 0.0003\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0007, Accuracy: 1835/2000 (92%)\n",
      "\n",
      "Train Epoch: 27 [0/50000 (0%)]\tLoss: 0.071042, Average: 0.000278\n",
      "Train Epoch: 27 [25600/50000 (51%)]\tLoss: 0.062197, Average: 0.000243\n",
      "\n",
      "Train set: Average loss: 0.0003\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0007, Accuracy: 1839/2000 (92%)\n",
      "\n",
      "Train Epoch: 28 [0/50000 (0%)]\tLoss: 0.068443, Average: 0.000267\n",
      "Train Epoch: 28 [25600/50000 (51%)]\tLoss: 0.060144, Average: 0.000235\n",
      "\n",
      "Train set: Average loss: 0.0003\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0007, Accuracy: 1842/2000 (92%)\n",
      "\n",
      "Train Epoch: 29 [0/50000 (0%)]\tLoss: 0.066963, Average: 0.000262\n",
      "Train Epoch: 29 [25600/50000 (51%)]\tLoss: 0.059461, Average: 0.000232\n",
      "\n",
      "Train set: Average loss: 0.0003\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0007, Accuracy: 1838/2000 (92%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, TRAIN_BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, TEST_BATCH_SIZE)\n",
    "\n",
    "epochs = 30\n",
    "lr = 0.1\n",
    "\n",
    "model = ConvNetOneLinearLayer().to(device)\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad) # !!!\n",
    "\n",
    "print(\"Parameters \", pytorch_total_params)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "loss_func = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Guardam el valor de pèrdua promig de cada iteració (època)\n",
    "train_l = np.zeros((epochs))\n",
    "test_l = np.zeros((epochs))\n",
    "\n",
    "# Bucle d'entrenament\n",
    "for epoch in range(0, epochs):\n",
    "    train_l[epoch] = train(model, device, train_loader, optimizer, epoch)\n",
    "    test_l[epoch]  = test(model, device, test_loader)\n",
    "\n",
    "if SAVE_MODEL:\n",
    "    torch.save(model, \"ConvNetOneLinearLayer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48c81111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_l, label = \"Train loss\")\n",
    "plt.plot(test_l, label = \"Test loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
