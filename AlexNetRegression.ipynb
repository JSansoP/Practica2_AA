{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "svpG5iA2OwpD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_8OFbgcdRhPm"
   },
   "outputs": [],
   "source": [
    "N_IMAGES_TRAIN = 50_000\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "TEST_BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1GD06pQiRS85"
   },
   "outputs": [],
   "source": [
    "# First we define a custom dataset class to be able to create the DataLoader properly\n",
    "\n",
    "class CustomImageDatasetCOLOR(torch.utils.data.Dataset):\n",
    "    def __init__(self, labels_file, img_dir, separator=',', img_type=\"png\",transform=None, max_images=None):\n",
    "        # As labels, we select the 'c' column of the dataset, which contains the number\n",
    "        # of circles of the image\n",
    "        aux = pd.read_csv(labels_file,sep=separator)\n",
    "        aux.drop(columns=aux.columns[0], axis=1,inplace=True)\n",
    "        aux.drop(columns=aux.columns[1:], axis=1, inplace=True)\n",
    "        self.img_labels = aux.to_numpy().squeeze()\n",
    "        if max_images is not None:\n",
    "            self.img_labels = self.img_labels[:max_images]\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.img_type = img_type\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # To get the images, we transform the index to a 5 long string (so 28 -> 00028)\n",
    "        # and we use that to read the image.\n",
    "        img_name = str(idx).zfill(5)+'.'+self.img_type\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        gray = cv2.imread(img_path,  cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.cvtColor(gray,cv2.COLOR_GRAY2RGB)\n",
    "        label = self.img_labels[idx,]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            image = image.float()\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ooGSxwuFPGi4"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128, 128))    \n",
    "    ])\n",
    "\n",
    "train_dataset = CustomImageDatasetCOLOR(labels_file='data/train/dades.csv', img_dir='data/train', separator=';', transform=transform)\n",
    "test_dataset = CustomImageDatasetCOLOR(labels_file='data/val/dades.csv', img_dir='data/val', separator=';', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, TRAIN_BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k5sKOQxZQFzH",
    "outputId": "24d646ba-6e93-44aa-977d-25fbec79376f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\sanso/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n",
      "C:\\Users\\sanso\\miniconda3\\envs\\torchCUDA\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now using the AlexNet\n",
    "AlexNet_model = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', weights=True)\n",
    "\n",
    "# Model description\n",
    "AlexNet_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8AZhPiqPQr9B",
    "outputId": "ee1bee1c-038b-4750-dbf8-2a80856d797c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (1): Flatten(start_dim=1, end_dim=-1)\n",
       "  (2): Linear(in_features=2304, out_features=256, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (5): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in AlexNet_model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "ModifiedAlexNet = nn.Sequential(AlexNet_model.features, nn.Flatten(1,-1), nn.Linear(2304,256), nn.ReLU(), nn.Linear(256,1),\n",
    "                               nn.ReLU())\n",
    "\n",
    "ModifiedAlexNet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZIQv4S9dR1k2"
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, log_interval=100, verbose=True):\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    loss_v = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        output = output.squeeze()\n",
    "        loss = loss_func(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0 and verbose:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Average: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item(), loss.item() / len(data)))\n",
    "        loss_v += loss.item()\n",
    "\n",
    "    loss_v /= len(train_loader.dataset)\n",
    "    print('\\nTrain set: Average loss: {:.4f}\\n'.format(loss_v))\n",
    " \n",
    "    return loss_v\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            output = output.squeeze()\n",
    "            test_loss += loss_func(output, target)\n",
    "            output = torch.round(output)\n",
    "            correct += output.eq(target.view_as(output)).sum().item()\n",
    " \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "id": "0-r0OuibR4RB",
    "outputId": "d87298dd-4e8e-40fb-aa72-f271df2219be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters  590337\n",
      "Train Epoch: 0 [0/50000 (0%)]\tLoss: 1.457660, Average: 0.011388\n",
      "Train Epoch: 0 [12800/50000 (26%)]\tLoss: 0.271293, Average: 0.002119\n",
      "Train Epoch: 0 [25600/50000 (51%)]\tLoss: 0.226939, Average: 0.001773\n",
      "Train Epoch: 0 [38400/50000 (77%)]\tLoss: 0.245166, Average: 0.001915\n",
      "\n",
      "Train set: Average loss: 0.0020\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0019, Accuracy: 1501/2000 (75%)\n",
      "\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 0.140530, Average: 0.001098\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 0.195171, Average: 0.001525\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 0.201542, Average: 0.001575\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 0.222529, Average: 0.001739\n",
      "\n",
      "Train set: Average loss: 0.0015\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0018, Accuracy: 1532/2000 (77%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.129951, Average: 0.001015\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 0.182225, Average: 0.001424\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 0.190756, Average: 0.001490\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 0.216374, Average: 0.001690\n",
      "\n",
      "Train set: Average loss: 0.0014\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1538/2000 (77%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.123901, Average: 0.000968\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 0.175605, Average: 0.001372\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.184191, Average: 0.001439\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 0.211432, Average: 0.001652\n",
      "\n",
      "Train set: Average loss: 0.0013\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 1551/2000 (78%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.118394, Average: 0.000925\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 0.172315, Average: 0.001346\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.179768, Average: 0.001404\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 0.208240, Average: 0.001627\n",
      "\n",
      "Train set: Average loss: 0.0013\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 1552/2000 (78%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.115916, Average: 0.000906\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.170233, Average: 0.001330\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.177353, Average: 0.001386\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.205050, Average: 0.001602\n",
      "\n",
      "Train set: Average loss: 0.0013\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 1558/2000 (78%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.114459, Average: 0.000894\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.168119, Average: 0.001313\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.173291, Average: 0.001354\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.203222, Average: 0.001588\n",
      "\n",
      "Train set: Average loss: 0.0012\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 1568/2000 (78%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.112568, Average: 0.000879\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.167658, Average: 0.001310\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.168202, Average: 0.001314\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.200554, Average: 0.001567\n",
      "\n",
      "Train set: Average loss: 0.0012\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 1578/2000 (79%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.110902, Average: 0.000866\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.164934, Average: 0.001289\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.162534, Average: 0.001270\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.199004, Average: 0.001555\n",
      "\n",
      "Train set: Average loss: 0.0012\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 1589/2000 (79%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.108760, Average: 0.000850\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.163334, Average: 0.001276\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.159992, Average: 0.001250\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.195528, Average: 0.001528\n",
      "\n",
      "Train set: Average loss: 0.0012\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 1589/2000 (79%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.109038, Average: 0.000852\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.161167, Average: 0.001259\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.156783, Average: 0.001225\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.191181, Average: 0.001494\n",
      "\n",
      "Train set: Average loss: 0.0012\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 1597/2000 (80%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.108882, Average: 0.000851\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 0.158586, Average: 0.001239\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.154033, Average: 0.001203\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 0.187285, Average: 0.001463\n",
      "\n",
      "Train set: Average loss: 0.0011\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 1595/2000 (80%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.109206, Average: 0.000853\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 0.156796, Average: 0.001225\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 0.150126, Average: 0.001173\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 0.185547, Average: 0.001450\n",
      "\n",
      "Train set: Average loss: 0.0011\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 1593/2000 (80%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.109300, Average: 0.000854\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 0.154759, Average: 0.001209\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 0.146942, Average: 0.001148\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 0.182791, Average: 0.001428\n",
      "\n",
      "Train set: Average loss: 0.0011\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 1588/2000 (79%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.109764, Average: 0.000858\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 0.152912, Average: 0.001195\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 0.144411, Average: 0.001128\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 0.181737, Average: 0.001420\n",
      "\n",
      "Train set: Average loss: 0.0011\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 1592/2000 (80%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.110674, Average: 0.000865\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 0.151414, Average: 0.001183\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 0.140747, Average: 0.001100\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 0.178154, Average: 0.001392\n",
      "\n",
      "Train set: Average loss: 0.0011\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 1594/2000 (80%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 0.113298, Average: 0.000885\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 0.149955, Average: 0.001172\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 0.138184, Average: 0.001080\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 0.175552, Average: 0.001372\n",
      "\n",
      "Train set: Average loss: 0.0011\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 1593/2000 (80%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 0.111734, Average: 0.000873\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 0.148207, Average: 0.001158\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 0.137083, Average: 0.001071\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 0.173326, Average: 0.001354\n",
      "\n",
      "Train set: Average loss: 0.0011\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 1595/2000 (80%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 0.112780, Average: 0.000881\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 0.146276, Average: 0.001143\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 0.136300, Average: 0.001065\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 0.170821, Average: 0.001335\n",
      "\n",
      "Train set: Average loss: 0.0010\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 1590/2000 (80%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.113124, Average: 0.000884\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 0.146017, Average: 0.001141\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 0.131696, Average: 0.001029\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 0.167867, Average: 0.001311\n",
      "\n",
      "Train set: Average loss: 0.0010\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 1591/2000 (80%)\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 0.114358, Average: 0.000893\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 0.142481, Average: 0.001113\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 0.131586, Average: 0.001028\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 0.164738, Average: 0.001287\n",
      "\n",
      "Train set: Average loss: 0.0010\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 1580/2000 (79%)\n",
      "\n",
      "Train Epoch: 21 [0/50000 (0%)]\tLoss: 0.116498, Average: 0.000910\n",
      "Train Epoch: 21 [12800/50000 (26%)]\tLoss: 0.141261, Average: 0.001104\n",
      "Train Epoch: 21 [25600/50000 (51%)]\tLoss: 0.129785, Average: 0.001014\n",
      "Train Epoch: 21 [38400/50000 (77%)]\tLoss: 0.162136, Average: 0.001267\n",
      "\n",
      "Train set: Average loss: 0.0010\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 1576/2000 (79%)\n",
      "\n",
      "Train Epoch: 22 [0/50000 (0%)]\tLoss: 0.116034, Average: 0.000907\n",
      "Train Epoch: 22 [12800/50000 (26%)]\tLoss: 0.140065, Average: 0.001094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22 [25600/50000 (51%)]\tLoss: 0.127846, Average: 0.000999\n",
      "Train Epoch: 22 [38400/50000 (77%)]\tLoss: 0.159316, Average: 0.001245\n",
      "\n",
      "Train set: Average loss: 0.0010\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 1582/2000 (79%)\n",
      "\n",
      "Train Epoch: 23 [0/50000 (0%)]\tLoss: 0.114083, Average: 0.000891\n",
      "Train Epoch: 23 [12800/50000 (26%)]\tLoss: 0.139512, Average: 0.001090\n",
      "Train Epoch: 23 [25600/50000 (51%)]\tLoss: 0.126791, Average: 0.000991\n",
      "Train Epoch: 23 [38400/50000 (77%)]\tLoss: 0.157841, Average: 0.001233\n",
      "\n",
      "Train set: Average loss: 0.0010\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 1583/2000 (79%)\n",
      "\n",
      "Train Epoch: 24 [0/50000 (0%)]\tLoss: 0.113639, Average: 0.000888\n",
      "Train Epoch: 24 [12800/50000 (26%)]\tLoss: 0.137286, Average: 0.001073\n",
      "Train Epoch: 24 [25600/50000 (51%)]\tLoss: 0.125186, Average: 0.000978\n",
      "Train Epoch: 24 [38400/50000 (77%)]\tLoss: 0.154484, Average: 0.001207\n",
      "\n",
      "Train set: Average loss: 0.0010\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 1578/2000 (79%)\n",
      "\n",
      "Train Epoch: 25 [0/50000 (0%)]\tLoss: 0.114007, Average: 0.000891\n",
      "Train Epoch: 25 [12800/50000 (26%)]\tLoss: 0.136431, Average: 0.001066\n",
      "Train Epoch: 25 [25600/50000 (51%)]\tLoss: 0.124263, Average: 0.000971\n",
      "Train Epoch: 25 [38400/50000 (77%)]\tLoss: 0.154060, Average: 0.001204\n",
      "\n",
      "Train set: Average loss: 0.0010\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 1564/2000 (78%)\n",
      "\n",
      "Train Epoch: 26 [0/50000 (0%)]\tLoss: 0.117374, Average: 0.000917\n",
      "Train Epoch: 26 [12800/50000 (26%)]\tLoss: 0.133771, Average: 0.001045\n",
      "Train Epoch: 26 [25600/50000 (51%)]\tLoss: 0.122480, Average: 0.000957\n",
      "Train Epoch: 26 [38400/50000 (77%)]\tLoss: 0.151799, Average: 0.001186\n",
      "\n",
      "Train set: Average loss: 0.0009\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1565/2000 (78%)\n",
      "\n",
      "Train Epoch: 27 [0/50000 (0%)]\tLoss: 0.118758, Average: 0.000928\n",
      "Train Epoch: 27 [12800/50000 (26%)]\tLoss: 0.133433, Average: 0.001042\n",
      "Train Epoch: 27 [25600/50000 (51%)]\tLoss: 0.120582, Average: 0.000942\n",
      "Train Epoch: 27 [38400/50000 (77%)]\tLoss: 0.150400, Average: 0.001175\n",
      "\n",
      "Train set: Average loss: 0.0009\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1561/2000 (78%)\n",
      "\n",
      "Train Epoch: 28 [0/50000 (0%)]\tLoss: 0.118918, Average: 0.000929\n",
      "Train Epoch: 28 [12800/50000 (26%)]\tLoss: 0.132450, Average: 0.001035\n",
      "Train Epoch: 28 [25600/50000 (51%)]\tLoss: 0.119641, Average: 0.000935\n",
      "Train Epoch: 28 [38400/50000 (77%)]\tLoss: 0.146308, Average: 0.001143\n",
      "\n",
      "Train set: Average loss: 0.0009\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1552/2000 (78%)\n",
      "\n",
      "Train Epoch: 29 [0/50000 (0%)]\tLoss: 0.120623, Average: 0.000942\n",
      "Train Epoch: 29 [12800/50000 (26%)]\tLoss: 0.130309, Average: 0.001018\n",
      "Train Epoch: 29 [25600/50000 (51%)]\tLoss: 0.117586, Average: 0.000919\n",
      "Train Epoch: 29 [38400/50000 (77%)]\tLoss: 0.144913, Average: 0.001132\n",
      "\n",
      "Train set: Average loss: 0.0009\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1553/2000 (78%)\n",
      "\n",
      "Train Epoch: 30 [0/50000 (0%)]\tLoss: 0.117377, Average: 0.000917\n",
      "Train Epoch: 30 [12800/50000 (26%)]\tLoss: 0.127258, Average: 0.000994\n",
      "Train Epoch: 30 [25600/50000 (51%)]\tLoss: 0.116936, Average: 0.000914\n",
      "Train Epoch: 30 [38400/50000 (77%)]\tLoss: 0.142297, Average: 0.001112\n",
      "\n",
      "Train set: Average loss: 0.0009\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1545/2000 (77%)\n",
      "\n",
      "Train Epoch: 31 [0/50000 (0%)]\tLoss: 0.119573, Average: 0.000934\n",
      "Train Epoch: 31 [12800/50000 (26%)]\tLoss: 0.126297, Average: 0.000987\n",
      "Train Epoch: 31 [25600/50000 (51%)]\tLoss: 0.115651, Average: 0.000904\n",
      "Train Epoch: 31 [38400/50000 (77%)]\tLoss: 0.137352, Average: 0.001073\n",
      "\n",
      "Train set: Average loss: 0.0009\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1551/2000 (78%)\n",
      "\n",
      "Train Epoch: 32 [0/50000 (0%)]\tLoss: 0.116610, Average: 0.000911\n",
      "Train Epoch: 32 [12800/50000 (26%)]\tLoss: 0.124224, Average: 0.000971\n",
      "Train Epoch: 32 [25600/50000 (51%)]\tLoss: 0.114541, Average: 0.000895\n",
      "Train Epoch: 32 [38400/50000 (77%)]\tLoss: 0.135133, Average: 0.001056\n",
      "\n",
      "Train set: Average loss: 0.0009\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1560/2000 (78%)\n",
      "\n",
      "Train Epoch: 33 [0/50000 (0%)]\tLoss: 0.111413, Average: 0.000870\n",
      "Train Epoch: 33 [12800/50000 (26%)]\tLoss: 0.123400, Average: 0.000964\n",
      "Train Epoch: 33 [25600/50000 (51%)]\tLoss: 0.114642, Average: 0.000896\n",
      "Train Epoch: 33 [38400/50000 (77%)]\tLoss: 0.132180, Average: 0.001033\n",
      "\n",
      "Train set: Average loss: 0.0009\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1565/2000 (78%)\n",
      "\n",
      "Train Epoch: 34 [0/50000 (0%)]\tLoss: 0.111051, Average: 0.000868\n",
      "Train Epoch: 34 [12800/50000 (26%)]\tLoss: 0.122995, Average: 0.000961\n",
      "Train Epoch: 34 [25600/50000 (51%)]\tLoss: 0.113674, Average: 0.000888\n",
      "Train Epoch: 34 [38400/50000 (77%)]\tLoss: 0.130248, Average: 0.001018\n",
      "\n",
      "Train set: Average loss: 0.0009\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1558/2000 (78%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "use_cuda = True\n",
    "torch.manual_seed(33)\n",
    "\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "epochs = 35\n",
    "lr = 0.001\n",
    "\n",
    "model = ModifiedAlexNet.to(device)\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Parameters \", pytorch_total_params)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "# Guardam el valor de pèrdua promig de cada iteració (època)\n",
    "train_l = np.zeros((epochs))\n",
    "test_l = np.zeros((epochs))\n",
    "\n",
    "# Bucle d'entrenament\n",
    "for epoch in range(0, epochs):\n",
    "    train_l[epoch] = train(model, device, train_loader, optimizer, epoch)\n",
    "    test_l[epoch]  = test(model, device, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"TransferAlexNet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_l[1:], label=\"Train loss\")\n",
    "plt.plot(test_l[1:], label=\"Test loss\")\n",
    "plt.title(\"Train and test losses\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
