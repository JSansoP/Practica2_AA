{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "svpG5iA2OwpD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_8OFbgcdRhPm"
   },
   "outputs": [],
   "source": [
    "N_IMAGES_TRAIN = 20_000\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "TEST_BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1GD06pQiRS85"
   },
   "outputs": [],
   "source": [
    "# First we define a custom dataset class to be able to create the DataLoader properly\n",
    "\n",
    "class CustomImageDatasetCOLOR(torch.utils.data.Dataset):\n",
    "    def __init__(self, labels_file, img_dir, separator=',', img_type=\"png\",transform=None, max_images=None):\n",
    "        # As labels, we select the 'c' column of the dataset, which contains the number\n",
    "        # of circles of the image\n",
    "        aux = pd.read_csv(labels_file,sep=separator)\n",
    "        aux.drop(columns=aux.columns[0], axis=1,inplace=True)\n",
    "        aux.drop(columns=aux.columns[1:], axis=1, inplace=True)\n",
    "        self.img_labels = aux.to_numpy().squeeze()\n",
    "        if max_images is not None:\n",
    "            self.img_labels = self.img_labels[:max_images]\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.img_type = img_type\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # To get the images, we transform the index to a 5 long string (so 28 -> 00028)\n",
    "        # and we use that to read the image.\n",
    "        img_name = str(idx).zfill(5)+'.'+self.img_type\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        gray = cv2.imread(img_path,  cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.cvtColor(gray,cv2.COLOR_GRAY2RGB)\n",
    "        label = self.img_labels[idx,]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            image = image.float()\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ooGSxwuFPGi4"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128, 128))    \n",
    "    ])\n",
    "\n",
    "train_dataset = CustomImageDatasetCOLOR(labels_file='data/train/dades.csv', img_dir='data/train', separator=';', transform=transform)\n",
    "test_dataset = CustomImageDatasetCOLOR(labels_file='data/val/dades.csv', img_dir='data/val', separator=';', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, TRAIN_BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k5sKOQxZQFzH",
    "outputId": "24d646ba-6e93-44aa-977d-25fbec79376f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\sanso/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n",
      "C:\\Users\\sanso\\miniconda3\\envs\\torchCUDA\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now using the AlexNet\n",
    "AlexNet_model = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', weights=True)\n",
    "\n",
    "# Model description\n",
    "AlexNet_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8AZhPiqPQr9B",
    "outputId": "ee1bee1c-038b-4750-dbf8-2a80856d797c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (1): Flatten(start_dim=1, end_dim=-1)\n",
       "  (2): Linear(in_features=2304, out_features=256, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in AlexNet_model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "ModifiedAlexNet = nn.Sequential(AlexNet_model.features, nn.Flatten(1,-1), nn.Linear(2304,256), nn.ReLU(), nn.Linear(256,1))\n",
    "\n",
    "ModifiedAlexNet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZIQv4S9dR1k2"
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, log_interval=100, verbose=True):\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    loss_v = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        output = output.squeeze()\n",
    "        loss = loss_func(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0 and verbose:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Average: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item(), loss.item() / len(data)))\n",
    "        loss_v += loss.item()\n",
    "\n",
    "    loss_v /= len(train_loader.dataset)\n",
    "    print('\\nTrain set: Average loss: {:.4f}\\n'.format(loss_v))\n",
    " \n",
    "    return loss_v\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            output = output.squeeze()\n",
    "            test_loss += loss_func(output, target)\n",
    "            output = torch.round(output)\n",
    "            correct += output.eq(target.view_as(output)).sum().item()\n",
    " \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "id": "0-r0OuibR4RB",
    "outputId": "d87298dd-4e8e-40fb-aa72-f271df2219be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters  590337\n",
      "Train Epoch: 0 [0/50000 (0%)]\tLoss: 2.228152, Average: 0.017407\n",
      "Train Epoch: 0 [12800/50000 (26%)]\tLoss: 0.237521, Average: 0.001856\n",
      "Train Epoch: 0 [25600/50000 (51%)]\tLoss: 0.228626, Average: 0.001786\n",
      "Train Epoch: 0 [38400/50000 (77%)]\tLoss: 0.233629, Average: 0.001825\n",
      "\n",
      "Train set: Average loss: 0.0145\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0019, Accuracy: 1490/2000 (74%)\n",
      "\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 0.144894, Average: 0.001132\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 0.186386, Average: 0.001456\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 0.210240, Average: 0.001642\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 0.212848, Average: 0.001663\n",
      "\n",
      "Train set: Average loss: 0.0015\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1527/2000 (76%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.135695, Average: 0.001060\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 0.174511, Average: 0.001363\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 0.201736, Average: 0.001576\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 0.214402, Average: 0.001675\n",
      "\n",
      "Train set: Average loss: 0.0014\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1524/2000 (76%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.132277, Average: 0.001033\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 0.169871, Average: 0.001327\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.196028, Average: 0.001531\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 0.211068, Average: 0.001649\n",
      "\n",
      "Train set: Average loss: 0.0014\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1550/2000 (78%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.139024, Average: 0.001086\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 0.169139, Average: 0.001321\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.194965, Average: 0.001523\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 0.207961, Average: 0.001625\n",
      "\n",
      "Train set: Average loss: 0.0014\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1543/2000 (77%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.139166, Average: 0.001087\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.166555, Average: 0.001301\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.192954, Average: 0.001507\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.207103, Average: 0.001618\n",
      "\n",
      "Train set: Average loss: 0.0014\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1551/2000 (78%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.138061, Average: 0.001079\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.170112, Average: 0.001329\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.188712, Average: 0.001474\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.207819, Average: 0.001624\n",
      "\n",
      "Train set: Average loss: 0.0014\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1560/2000 (78%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.135557, Average: 0.001059\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.179958, Average: 0.001406\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.187649, Average: 0.001466\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.205176, Average: 0.001603\n",
      "\n",
      "Train set: Average loss: 0.0014\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1568/2000 (78%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.132730, Average: 0.001037\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.168582, Average: 0.001317\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.184838, Average: 0.001444\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.205136, Average: 0.001603\n",
      "\n",
      "Train set: Average loss: 0.0014\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1570/2000 (78%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.131719, Average: 0.001029\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.174419, Average: 0.001363\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.185229, Average: 0.001447\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.202795, Average: 0.001584\n",
      "\n",
      "Train set: Average loss: 0.0014\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1573/2000 (79%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.131541, Average: 0.001028\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.170165, Average: 0.001329\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.185013, Average: 0.001445\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.206526, Average: 0.001613\n",
      "\n",
      "Train set: Average loss: 0.0013\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1557/2000 (78%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.130105, Average: 0.001016\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 0.173039, Average: 0.001352\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.184724, Average: 0.001443\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 0.206607, Average: 0.001614\n",
      "\n",
      "Train set: Average loss: 0.0013\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 1566/2000 (78%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.132086, Average: 0.001032\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 0.170926, Average: 0.001335\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 0.184212, Average: 0.001439\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 0.206616, Average: 0.001614\n",
      "\n",
      "Train set: Average loss: 0.0013\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1561/2000 (78%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.133479, Average: 0.001043\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 0.170484, Average: 0.001332\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 0.186111, Average: 0.001454\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 0.205806, Average: 0.001608\n",
      "\n",
      "Train set: Average loss: 0.0013\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1562/2000 (78%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.134463, Average: 0.001050\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 0.168205, Average: 0.001314\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 0.187400, Average: 0.001464\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 0.208484, Average: 0.001629\n",
      "\n",
      "Train set: Average loss: 0.0013\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1565/2000 (78%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.133925, Average: 0.001046\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 0.167493, Average: 0.001309\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 0.187298, Average: 0.001463\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 0.208897, Average: 0.001632\n",
      "\n",
      "Train set: Average loss: 0.0013\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1569/2000 (78%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 0.136242, Average: 0.001064\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 0.167948, Average: 0.001312\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 0.186861, Average: 0.001460\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 0.211684, Average: 0.001654\n",
      "\n",
      "Train set: Average loss: 0.0013\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1560/2000 (78%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 0.135813, Average: 0.001061\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 0.171771, Average: 0.001342\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 0.189171, Average: 0.001478\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 0.204777, Average: 0.001600\n",
      "\n",
      "Train set: Average loss: 0.0013\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1562/2000 (78%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 0.136799, Average: 0.001069\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 0.169984, Average: 0.001328\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 0.187220, Average: 0.001463\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 0.205682, Average: 0.001607\n",
      "\n",
      "Train set: Average loss: 0.0013\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1566/2000 (78%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.135045, Average: 0.001055\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 0.170909, Average: 0.001335\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 0.186538, Average: 0.001457\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 0.206736, Average: 0.001615\n",
      "\n",
      "Train set: Average loss: 0.0013\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 1569/2000 (78%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "use_cuda = True\n",
    "torch.manual_seed(33)\n",
    "\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "epochs = 20\n",
    "lr = 0.01\n",
    "\n",
    "model = ModifiedAlexNet.to(device)\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Parameters \", pytorch_total_params)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "# Guardam el valor de pèrdua promig de cada iteració (època)\n",
    "train_l = np.zeros((epochs))\n",
    "test_l = np.zeros((epochs))\n",
    "\n",
    "# Bucle d'entrenament\n",
    "for epoch in range(0, epochs):\n",
    "    train_l[epoch] = train(model, device, train_loader, optimizer, epoch)\n",
    "    test_l[epoch]  = test(model, device, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"TransferAlexNet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_l, label=\"Train loss\")\n",
    "plt.plot(test_l, label=\"Test loss\")\n",
    "plt.title(\"Train and test losses\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
